{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face ðŸ¤— NLP Transformers pipelines with ONNX\n",
    "\n",
    "![logo](assets/logo.png)\n",
    "\n",
    "*This project is linked to the Medium blog post: [How to use Hugging Face ðŸ¤— Transformers with ONNX in realÂ world]()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working environment\n",
    "\n",
    "First of all, you need to install all required dependencies. It is recommended to use and isolated environment to avoid conflicts.\n",
    "\n",
    "You can use any package manager you want. I recommend [`conda`](https://conda.io/).\n",
    "\n",
    "```bash\n",
    "conda create -y -n hf-onnx python=3.8\n",
    "```\n",
    "\n",
    "All required dependencies are listed in the `requirements.txt` file. To install them, run the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from onnxruntime import (\n",
    "    InferenceSession, SessionOptions, GraphOptimizationLevel\n",
    ")\n",
    "from transformers import (\n",
    "    TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = SessionOptions()\n",
    "options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "session = InferenceSession(\n",
    "    \"onnx/model.onnx\", sess_options=options, providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "session.disable_fallback()\n",
    "\n",
    "\n",
    "class OnnxTokenClassificationPipeline(TokenClassificationPipeline):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    \n",
    "    def _forward(self, model_inputs):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \"\"\"\n",
    "        special_tokens_mask = model_inputs.pop(\"special_tokens_mask\")\n",
    "        offset_mapping = model_inputs.pop(\"offset_mapping\", None)\n",
    "        sentence = model_inputs.pop(\"sentence\")\n",
    "\n",
    "        inputs = {k: v.cpu().detach().numpy() for k, v in model_inputs.items()}\n",
    "        outputs_name = session.get_outputs()[0].name\n",
    "\n",
    "        logits = session.run(output_names=[outputs_name], input_feed=inputs)[0]\n",
    "\n",
    "        return {\n",
    "            \"logits\": torch.tensor(logits),\n",
    "            \"special_tokens_mask\": special_tokens_mask,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "            \"sentence\": sentence,\n",
    "            **model_inputs,\n",
    "        }\n",
    "\n",
    "    \n",
    "    def preprocess(self, sentence, offset_mapping=None):\n",
    "        truncation = True if self.tokenizer.model_max_length and self.tokenizer.model_max_length > 0 else False\n",
    "        model_inputs = self.tokenizer(\n",
    "            sentence,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=self.framework,\n",
    "            truncation=truncation,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_offsets_mapping=self.tokenizer.is_fast,\n",
    "        )\n",
    "        if offset_mapping:\n",
    "            model_inputs[\"offset_mapping\"] = offset_mapping\n",
    "\n",
    "        model_inputs[\"sentence\"] = sentence\n",
    "\n",
    "        return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_from_hub = \"Jean-Baptiste/roberta-large-ner-english\"\n",
    "model_name_from_hub = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_from_hub)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name_from_hub)\n",
    "\n",
    "ner_pipeline = OnnxTokenClassificationPipeline(\n",
    "    task=\"ner\", \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    aggregation_strategy=\"simple\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9978969,\n",
       "  'word': 'Apple',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9981243,\n",
       "  'word': 'Steve Jobs',\n",
       "  'start': 29,\n",
       "  'end': 39},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9741297,\n",
       "  'word': 'Steve Wozniak',\n",
       "  'start': 41,\n",
       "  'end': 54},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.99970996,\n",
       "  'word': 'Ronald Wayne',\n",
       "  'start': 59,\n",
       "  'end': 71},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.86664414,\n",
       "  'word': 'Wozniak',\n",
       "  'start': 92,\n",
       "  'end': 99},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99852806,\n",
       "  'word': 'Apple I',\n",
       "  'start': 102,\n",
       "  'end': 109}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Apple was founded in 1976 by Steve Jobs, Steve Wozniak and Ronald Wayne to develop and sell Wozniak's Apple I personal computer\"\n",
    "\n",
    "ner_pipeline(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0be00ba07bf63a0c73ab9bd0f7846fd29739e80e837fef3831f52181d58986e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('onnx-hf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
